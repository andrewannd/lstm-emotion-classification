{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47488aa-1a4c-4bb5-9d07-2534582d53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from tokenizers import Tokenizer, models, trainers\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "dataset = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]\n",
    "# Tokenization\n",
    "vocab_n = 5000\n",
    "sequence_len = 64\n",
    "\n",
    "# Initialize a tokenizer using BPE (Byte Pair Encoding)\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.enable_padding(length=sequence_len)\n",
    "tokenizer.enable_truncation(max_length=sequence_len)\n",
    "tokenizer_trainer = trainers.BpeTrainer(vocab_size=vocab_n)\n",
    "tokenizer.train_from_iterator(train_data[\"text\"], trainer=tokenizer_trainer)\n",
    "def preprocess_text(text: str, tokenizer: Tokenizer):\n",
    "    \"\"\" \n",
    "    Helper function to tokenize text and return corresponding token IDs as tensors.\n",
    "\n",
    "    Args:\n",
    "        text, str: Text instance from training data.\n",
    "        tokenizer, Tokenizer: The respective tokenizer to be used for tokenization.\n",
    "    Returns:\n",
    "        Tensor: One-dimensional PyTorch tensor with token IDs.\n",
    "    \"\"\"\n",
    "    return torch.tensor(tokenizer.encode(text).ids)\n",
    "\n",
    "\n",
    "def preprocess_label(label: int):\n",
    "    \"\"\" \n",
    "    Helper function to return label as tensor.\n",
    "\n",
    "    Args:\n",
    "        label, int: Label from instance.\n",
    "    Returns:\n",
    "        Tensor: One-dimensional PyTorch tensor containing the label index.\n",
    "    \"\"\"\n",
    "    return torch.tensor(label)\n",
    "\n",
    "\n",
    "def preprocess(data: dict, tokenizer: Tokenizer):\n",
    "    \"\"\" \n",
    "    Transforms input dataset to tokenized vector representations.\n",
    "\n",
    "    Args:\n",
    "        data, dict: Dictionary with text instances and labels.\n",
    "        tokenizer, Tokenizer: The respective tokenizer to be used for tokenization.\n",
    "    Returns:\n",
    "        list: List with tensors for the input texts and labels.\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "\n",
    "    for text, label in zip(data[\"text\"], data[\"label\"]):\n",
    "        input = preprocess_text(text, tokenizer)\n",
    "        label = preprocess_label(label)\n",
    "        \n",
    "        instances.append((input, label))\n",
    "\n",
    "    return instances\n",
    "train_instances = preprocess(train_data, tokenizer)\n",
    "val_instances = preprocess(validation_data, tokenizer)\n",
    "test_instances = preprocess(test_data, tokenizer)\n",
    "# Batching for LSTM input\n",
    "\n",
    "def batching_lstm(instances: list, batch_size: int, shuffle: bool):\n",
    "    \"\"\"\n",
    "    Batching for LSTM input: with padding support.\n",
    "\n",
    "    Args:\n",
    "        instances: List of (input_tensor, label_tensor) pairs.\n",
    "        batch_size: Number of instances per batch.\n",
    "        shuffle: Whether to shuffle the dataset before batching.\n",
    "    \n",
    "    Returns:\n",
    "        batches: List of (padded_input_tensor, label_tensor) for each batch.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        random.shuffle(instances)\n",
    "\n",
    "    batches = []\n",
    "\n",
    "    for i in range(0, len(instances), batch_size):\n",
    "        batch = instances[i : i + batch_size]\n",
    "\n",
    "        # Take out a batch of inputs and labels\n",
    "        batch_inputs = [item[0] for item in batch]  # list of tensors (seq_len,)\n",
    "        batch_labels = torch.stack([item[1] for item in batch])  # tensor of shape [batch_size]\n",
    "\n",
    "        # Automatic padding becomes [batch_size, max_seq_len]\n",
    "        padded_inputs = pad_sequence(batch_inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "        batches.append((padded_inputs, batch_labels))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a6701be-e017-4873-883f-6fc0b062fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, padding_idx):\n",
    "        super(CNN_Classifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # [batch, seq_len, emb_dim]\n",
    "        embedded = embedded.transpose(1, 2)  # [batch, emb_dim, seq_len]\n",
    "        \n",
    "        conv1_out = F.relu(self.conv1(embedded))  # [batch, 100, seq_len]\n",
    "        conv2_out = F.relu(self.conv2(conv1_out))  # [batch, 100, seq_len]\n",
    "        \n",
    "        return self.dropout(conv2_out.transpose(1, 2))  # [batch, seq_len, 100]\n",
    "\n",
    "class LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, padding_idx=None): \n",
    "        super(LSTM_Classifier, self).__init__()\n",
    "\n",
    "        # Single-layer bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Fully connected layer, output 6 types of emotions\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, cnn_features):\n",
    "         # cnn_features: [batch, seq_len, 100]\n",
    "        lstm_out, (hidden, _) = self.lstm(cnn_features)\n",
    "\n",
    "        # Take the last hidden layer of the forward and reverse directions and concatenate them\n",
    "        hidden_forward = hidden[-2, :, :]  # [batch, hidden_dim]\n",
    "        hidden_backward = hidden[-1, :, :]  # [batch, hidden_dim]\n",
    "        combined = torch.cat((hidden_forward, hidden_backward), dim=1)  # [batch, hidden_dim * 2]\n",
    "\n",
    "        return self.fc(self.dropout(combined))  # [batch, output_dim]\n",
    "    \n",
    "# Get the vocabulary dictionary from the tokenizer (word → ID)\n",
    "word2idx = tokenizer.get_vocab()  # e.g., {'i': 4, 'love': 5, 'this': 6, ...}\n",
    "\n",
    "# Reversal\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "padding_idx = word2idx.get(\"[PAD]\", 0) \n",
    "\n",
    "class CNN_LSTM_Ensemble(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx):\n",
    "        super(CNN_LSTM_Ensemble, self).__init__()\n",
    "        self.cnn = CNN_Classifier(vocab_size=vocab_size, embedding_dim=embedding_dim, output_dim=100, padding_idx=padding_idx)\n",
    "        self.lstm = LSTM_Classifier(input_dim=100, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "        self.fc = nn.Linear(output_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x)  # [batch, seq_len, 100]\n",
    "        return self.lstm(cnn_features)  # [batch, output_dim]\n",
    "        \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_and_evaluate(model, train_batches, val_batches, num_epochs=25, lr=1e-3, device=\"gpu\"):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for batch_x, batch_y in train_batches:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)  # shape: [batch_size, 6]\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        # ---- verify ----\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for val_x, val_y in val_batches:\n",
    "                val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "                val_out = model(val_x)\n",
    "                val_pred = torch.argmax(val_out, dim=1)\n",
    "                val_preds.extend(val_pred.cpu().numpy())\n",
    "                val_labels.extend(val_y.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {sum(train_losses)/len(train_losses):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | F1: {train_f1:.4f} || \"\n",
    "              f\"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cc2113a-12f0-412f-8c0a-bccd4f2f2b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train Loss: 1.4742 | Train Acc: 0.4093 | F1: 0.3411 || Val Acc: 0.5630 | Val F1: 0.4939\n",
      "Epoch 2/25 | Train Loss: 0.8787 | Train Acc: 0.6914 | F1: 0.6578 || Val Acc: 0.7625 | Val F1: 0.7408\n",
      "Epoch 3/25 | Train Loss: 0.4917 | Train Acc: 0.8257 | F1: 0.8198 || Val Acc: 0.8280 | Val F1: 0.8291\n",
      "Epoch 4/25 | Train Loss: 0.3176 | Train Acc: 0.8904 | F1: 0.8895 || Val Acc: 0.8620 | Val F1: 0.8605\n",
      "Epoch 5/25 | Train Loss: 0.2182 | Train Acc: 0.9230 | F1: 0.9228 || Val Acc: 0.8775 | Val F1: 0.8772\n",
      "Epoch 6/25 | Train Loss: 0.1648 | Train Acc: 0.9417 | F1: 0.9417 || Val Acc: 0.8865 | Val F1: 0.8864\n",
      "Epoch 7/25 | Train Loss: 0.1249 | Train Acc: 0.9561 | F1: 0.9561 || Val Acc: 0.8905 | Val F1: 0.8911\n",
      "Epoch 8/25 | Train Loss: 0.0994 | Train Acc: 0.9654 | F1: 0.9654 || Val Acc: 0.8945 | Val F1: 0.8944\n",
      "Epoch 9/25 | Train Loss: 0.0744 | Train Acc: 0.9754 | F1: 0.9754 || Val Acc: 0.9005 | Val F1: 0.9004\n",
      "Epoch 10/25 | Train Loss: 0.0858 | Train Acc: 0.9729 | F1: 0.9729 || Val Acc: 0.8855 | Val F1: 0.8847\n",
      "Epoch 11/25 | Train Loss: 0.0600 | Train Acc: 0.9806 | F1: 0.9806 || Val Acc: 0.8900 | Val F1: 0.8890\n",
      "Epoch 12/25 | Train Loss: 0.0419 | Train Acc: 0.9870 | F1: 0.9870 || Val Acc: 0.8870 | Val F1: 0.8860\n",
      "Epoch 13/25 | Train Loss: 0.0323 | Train Acc: 0.9892 | F1: 0.9892 || Val Acc: 0.8935 | Val F1: 0.8932\n",
      "Epoch 14/25 | Train Loss: 0.0265 | Train Acc: 0.9916 | F1: 0.9916 || Val Acc: 0.8965 | Val F1: 0.8962\n",
      "Epoch 15/25 | Train Loss: 0.0264 | Train Acc: 0.9918 | F1: 0.9918 || Val Acc: 0.8930 | Val F1: 0.8934\n",
      "Epoch 16/25 | Train Loss: 0.0349 | Train Acc: 0.9898 | F1: 0.9898 || Val Acc: 0.8955 | Val F1: 0.8946\n",
      "Epoch 17/25 | Train Loss: 0.0335 | Train Acc: 0.9886 | F1: 0.9886 || Val Acc: 0.8960 | Val F1: 0.8953\n",
      "Epoch 18/25 | Train Loss: 0.0259 | Train Acc: 0.9921 | F1: 0.9921 || Val Acc: 0.9015 | Val F1: 0.9013\n",
      "Epoch 19/25 | Train Loss: 0.0168 | Train Acc: 0.9947 | F1: 0.9947 || Val Acc: 0.8970 | Val F1: 0.8965\n",
      "Epoch 20/25 | Train Loss: 0.0376 | Train Acc: 0.9890 | F1: 0.9890 || Val Acc: 0.8965 | Val F1: 0.8961\n",
      "Epoch 21/25 | Train Loss: 0.0684 | Train Acc: 0.9799 | F1: 0.9799 || Val Acc: 0.8915 | Val F1: 0.8913\n",
      "Epoch 22/25 | Train Loss: 0.0309 | Train Acc: 0.9902 | F1: 0.9902 || Val Acc: 0.9020 | Val F1: 0.9016\n",
      "Epoch 23/25 | Train Loss: 0.0126 | Train Acc: 0.9960 | F1: 0.9960 || Val Acc: 0.9020 | Val F1: 0.9017\n",
      "Epoch 24/25 | Train Loss: 0.0108 | Train Acc: 0.9965 | F1: 0.9965 || Val Acc: 0.8980 | Val F1: 0.8980\n",
      "Epoch 25/25 | Train Loss: 0.0092 | Train Acc: 0.9965 | F1: 0.9965 || Val Acc: 0.8990 | Val F1: 0.8986\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=len(word2idx),        # vocabulary size\n",
    "    embedding_dim=100,               # Dimensions of word vectors\n",
    "    hidden_dim=128,                  # Hidden layer dimensions\n",
    "    output_dim=6,                    # The number of output categories\n",
    "    padding_idx=word2idx.get(\"[PAD]\", 0)  # Index of pad token\n",
    ")\n",
    "train_instances = preprocess(dataset[\"train\"], tokenizer)\n",
    "val_instances = preprocess(dataset[\"validation\"], tokenizer)\n",
    "\n",
    "train_batches = batching_lstm(train_instances, batch_size=32, shuffle=True)\n",
    "val_batches = batching_lstm(val_instances, batch_size=32, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_and_evaluate(model, train_batches, val_batches, num_epochs=25, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07e1abf2-6dcd-4a3d-8643-e21b5c664af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.92      0.94      0.93       550\n",
      "         joy       0.91      0.93      0.92       704\n",
      "        love       0.84      0.81      0.83       178\n",
      "       anger       0.91      0.88      0.90       275\n",
      "        fear       0.85      0.83      0.84       212\n",
      "    surprise       0.82      0.79      0.81        81\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.88      0.86      0.87      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the label name order\n",
    "label_names = dataset[\"train\"].features[\"label\"].names  # ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "\n",
    "# Model prediction validation set\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_batches:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        true_labels.extend(y_batch.cpu().numpy())\n",
    "        pred_labels.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print each category's precision, recall, f1-score\n",
    "print(classification_report(true_labels, pred_labels, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54d764f3-a6e6-4f97-8813-dc7be4bebad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported: True\n",
      "CUDA version: 11.8\n",
      "Current device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA is supported:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Current device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"无\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
